{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":8746997,"sourceType":"datasetVersion","datasetId":5252742}],"dockerImageVersionId":30732,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import os\nimport pandas as pd\nimport sys\nimport warnings\nif not sys.warnoptions:\n    warnings.simplefilter(\"ignore\")\nwarnings.filterwarnings(\"ignore\", category=DeprecationWarning) ","metadata":{"execution":{"iopub.status.busy":"2024-07-02T10:25:02.796380Z","iopub.execute_input":"2024-07-02T10:25:02.796750Z","iopub.status.idle":"2024-07-02T10:25:03.984467Z","shell.execute_reply.started":"2024-07-02T10:25:02.796722Z","shell.execute_reply":"2024-07-02T10:25:03.983089Z"},"trusted":true},"execution_count":1,"outputs":[]},{"cell_type":"markdown","source":"# RAVDESS","metadata":{}},{"cell_type":"code","source":"# Define the path to your RAVDESS data\nravdess_path = \"/kaggle/input/emotion-sound-data/archive/audio_speech_actors_01-24/\"\n\n# List all files in the directory\nravdess_files = [f for f in os.listdir(ravdess_path) if f.endswith('.wav')]","metadata":{"execution":{"iopub.status.busy":"2024-07-02T10:25:03.986538Z","iopub.execute_input":"2024-07-02T10:25:03.986978Z","iopub.status.idle":"2024-07-02T10:25:03.997560Z","shell.execute_reply.started":"2024-07-02T10:25:03.986947Z","shell.execute_reply":"2024-07-02T10:25:03.996123Z"},"trusted":true},"execution_count":2,"outputs":[]},{"cell_type":"code","source":"# Display the first few filenames\nprint(ravdess_files[:5])","metadata":{"execution":{"iopub.status.busy":"2024-07-02T10:25:03.999370Z","iopub.execute_input":"2024-07-02T10:25:04.000246Z","iopub.status.idle":"2024-07-02T10:25:04.009467Z","shell.execute_reply.started":"2024-07-02T10:25:04.000199Z","shell.execute_reply":"2024-07-02T10:25:04.008255Z"},"trusted":true},"execution_count":3,"outputs":[{"name":"stdout","text":"[]\n","output_type":"stream"}]},{"cell_type":"code","source":"ravdess_directory_list = os.listdir(ravdess_path)","metadata":{"execution":{"iopub.status.busy":"2024-07-02T10:25:04.011886Z","iopub.execute_input":"2024-07-02T10:25:04.012278Z","iopub.status.idle":"2024-07-02T10:25:04.019801Z","shell.execute_reply.started":"2024-07-02T10:25:04.012245Z","shell.execute_reply":"2024-07-02T10:25:04.018674Z"},"trusted":true},"execution_count":4,"outputs":[]},{"cell_type":"code","source":"file_emotion = []\nfile_path = []\nfor dir in ravdess_directory_list:\n    # as their are 20 different actors in our previous directory we need to extract files for each actor.\n    actor = os.listdir(ravdess_path + dir)\n    for file in actor:\n        part = file.split('.')[0]\n        part = part.split('-')\n        # third part in each file represents the emotion associated to that file.\n        file_emotion.append(int(part[2]))\n        file_path.append(ravdess_path + dir + '/' + file)","metadata":{"execution":{"iopub.status.busy":"2024-07-02T10:25:04.021278Z","iopub.execute_input":"2024-07-02T10:25:04.021724Z","iopub.status.idle":"2024-07-02T10:25:04.455593Z","shell.execute_reply.started":"2024-07-02T10:25:04.021684Z","shell.execute_reply":"2024-07-02T10:25:04.454261Z"},"trusted":true},"execution_count":5,"outputs":[]},{"cell_type":"code","source":"# dataframe for emotion of files\nemotion_df = pd.DataFrame(file_emotion, columns=['Emotions'])","metadata":{"execution":{"iopub.status.busy":"2024-07-02T10:25:04.456860Z","iopub.execute_input":"2024-07-02T10:25:04.457177Z","iopub.status.idle":"2024-07-02T10:25:04.464482Z","shell.execute_reply.started":"2024-07-02T10:25:04.457147Z","shell.execute_reply":"2024-07-02T10:25:04.463454Z"},"trusted":true},"execution_count":6,"outputs":[]},{"cell_type":"code","source":"# dataframe for path of files.\npath_df = pd.DataFrame(file_path, columns=['Path'])\nRavdess_df = pd.concat([emotion_df, path_df], axis=1)","metadata":{"execution":{"iopub.status.busy":"2024-07-02T10:25:04.465895Z","iopub.execute_input":"2024-07-02T10:25:04.466247Z","iopub.status.idle":"2024-07-02T10:25:04.478286Z","shell.execute_reply.started":"2024-07-02T10:25:04.466193Z","shell.execute_reply":"2024-07-02T10:25:04.477207Z"},"trusted":true},"execution_count":7,"outputs":[]},{"cell_type":"code","source":"# changing integers to actual emotions.\nRavdess_df.Emotions.replace({1:'neutral', 2:'calm', 3:'happy', 4:'sad', 5:'angry', 6:'fear', 7:'disgust', 8:'surprise'}, inplace=True)\nRavdess_df.head()","metadata":{"execution":{"iopub.status.busy":"2024-07-02T10:25:04.479798Z","iopub.execute_input":"2024-07-02T10:25:04.480522Z","iopub.status.idle":"2024-07-02T10:25:04.510128Z","shell.execute_reply.started":"2024-07-02T10:25:04.480482Z","shell.execute_reply":"2024-07-02T10:25:04.509021Z"},"trusted":true},"execution_count":8,"outputs":[{"execution_count":8,"output_type":"execute_result","data":{"text/plain":"   Emotions                                               Path\n0  surprise  /kaggle/input/emotion-sound-data/archive/audio...\n1   neutral  /kaggle/input/emotion-sound-data/archive/audio...\n2   disgust  /kaggle/input/emotion-sound-data/archive/audio...\n3   disgust  /kaggle/input/emotion-sound-data/archive/audio...\n4   neutral  /kaggle/input/emotion-sound-data/archive/audio...","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Emotions</th>\n      <th>Path</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>surprise</td>\n      <td>/kaggle/input/emotion-sound-data/archive/audio...</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>neutral</td>\n      <td>/kaggle/input/emotion-sound-data/archive/audio...</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>disgust</td>\n      <td>/kaggle/input/emotion-sound-data/archive/audio...</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>disgust</td>\n      <td>/kaggle/input/emotion-sound-data/archive/audio...</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>neutral</td>\n      <td>/kaggle/input/emotion-sound-data/archive/audio...</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}]},{"cell_type":"code","source":"# Display the first few filenames\nprint(Ravdess_df[:8])","metadata":{"execution":{"iopub.status.busy":"2024-07-02T10:25:04.511289Z","iopub.execute_input":"2024-07-02T10:25:04.511629Z","iopub.status.idle":"2024-07-02T10:25:04.518760Z","shell.execute_reply.started":"2024-07-02T10:25:04.511600Z","shell.execute_reply":"2024-07-02T10:25:04.517692Z"},"trusted":true},"execution_count":9,"outputs":[{"name":"stdout","text":"   Emotions                                               Path\n0  surprise  /kaggle/input/emotion-sound-data/archive/audio...\n1   neutral  /kaggle/input/emotion-sound-data/archive/audio...\n2   disgust  /kaggle/input/emotion-sound-data/archive/audio...\n3   disgust  /kaggle/input/emotion-sound-data/archive/audio...\n4   neutral  /kaggle/input/emotion-sound-data/archive/audio...\n5      fear  /kaggle/input/emotion-sound-data/archive/audio...\n6       sad  /kaggle/input/emotion-sound-data/archive/audio...\n7   neutral  /kaggle/input/emotion-sound-data/archive/audio...\n","output_type":"stream"}]},{"cell_type":"markdown","source":"# Crema DataFrame","metadata":{}},{"cell_type":"code","source":"cremad_path = \"/kaggle/input/emotion-sound-data/sound2/AudioWAV/\"\ncremad_files = [f for f in os.listdir(cremad_path) if f.endswith('.wav')]\nprint(cremad_files[:5])\n","metadata":{"execution":{"iopub.status.busy":"2024-07-02T10:25:04.522830Z","iopub.execute_input":"2024-07-02T10:25:04.523182Z","iopub.status.idle":"2024-07-02T10:25:04.758638Z","shell.execute_reply.started":"2024-07-02T10:25:04.523152Z","shell.execute_reply":"2024-07-02T10:25:04.757474Z"},"trusted":true},"execution_count":10,"outputs":[{"name":"stdout","text":"['1028_TSI_DIS_XX.wav', '1075_IEO_HAP_LO.wav', '1084_ITS_HAP_XX.wav', '1067_IWW_DIS_XX.wav', '1066_TIE_DIS_XX.wav']\n","output_type":"stream"}]},{"cell_type":"code","source":"crema_directory_list = os.listdir(cremad_path)\n\nfile_emotion = []\nfile_path = []","metadata":{"execution":{"iopub.status.busy":"2024-07-02T10:25:04.759808Z","iopub.execute_input":"2024-07-02T10:25:04.760101Z","iopub.status.idle":"2024-07-02T10:25:04.768264Z","shell.execute_reply.started":"2024-07-02T10:25:04.760061Z","shell.execute_reply":"2024-07-02T10:25:04.767332Z"},"trusted":true},"execution_count":11,"outputs":[]},{"cell_type":"code","source":"for file in crema_directory_list:\n    # storing file paths\n    file_path.append(cremad_path + file)\n    # storing file emotions\n    part=file.split('_')\n    if part[2] == 'SAD':\n        file_emotion.append('sad')\n    elif part[2] == 'ANG':\n        file_emotion.append('angry')\n    elif part[2] == 'DIS':\n        file_emotion.append('disgust')\n    elif part[2] == 'FEA':\n        file_emotion.append('fear')\n    elif part[2] == 'HAP':\n        file_emotion.append('happy')\n    elif part[2] == 'NEU':\n        file_emotion.append('neutral')\n    else:\n        file_emotion.append('Unknown')","metadata":{"execution":{"iopub.status.busy":"2024-07-02T10:25:04.769651Z","iopub.execute_input":"2024-07-02T10:25:04.770053Z","iopub.status.idle":"2024-07-02T10:25:04.787624Z","shell.execute_reply.started":"2024-07-02T10:25:04.770014Z","shell.execute_reply":"2024-07-02T10:25:04.786516Z"},"trusted":true},"execution_count":12,"outputs":[]},{"cell_type":"code","source":"# dataframe for emotion of files\nemotion_df = pd.DataFrame(file_emotion, columns=['Emotions'])","metadata":{"execution":{"iopub.status.busy":"2024-07-02T10:25:04.789327Z","iopub.execute_input":"2024-07-02T10:25:04.789740Z","iopub.status.idle":"2024-07-02T10:25:04.804124Z","shell.execute_reply.started":"2024-07-02T10:25:04.789702Z","shell.execute_reply":"2024-07-02T10:25:04.803005Z"},"trusted":true},"execution_count":13,"outputs":[]},{"cell_type":"code","source":"# dataframe for path of files.\npath_df = pd.DataFrame(file_path, columns=['Path'])\nCrema_df = pd.concat([emotion_df, path_df], axis=1)\nCrema_df.head()","metadata":{"execution":{"iopub.status.busy":"2024-07-02T10:25:04.805788Z","iopub.execute_input":"2024-07-02T10:25:04.806848Z","iopub.status.idle":"2024-07-02T10:25:04.822250Z","shell.execute_reply.started":"2024-07-02T10:25:04.806805Z","shell.execute_reply":"2024-07-02T10:25:04.821113Z"},"trusted":true},"execution_count":14,"outputs":[{"execution_count":14,"output_type":"execute_result","data":{"text/plain":"  Emotions                                               Path\n0  disgust  /kaggle/input/emotion-sound-data/sound2/AudioW...\n1    happy  /kaggle/input/emotion-sound-data/sound2/AudioW...\n2    happy  /kaggle/input/emotion-sound-data/sound2/AudioW...\n3  disgust  /kaggle/input/emotion-sound-data/sound2/AudioW...\n4  disgust  /kaggle/input/emotion-sound-data/sound2/AudioW...","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Emotions</th>\n      <th>Path</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>disgust</td>\n      <td>/kaggle/input/emotion-sound-data/sound2/AudioW...</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>happy</td>\n      <td>/kaggle/input/emotion-sound-data/sound2/AudioW...</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>happy</td>\n      <td>/kaggle/input/emotion-sound-data/sound2/AudioW...</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>disgust</td>\n      <td>/kaggle/input/emotion-sound-data/sound2/AudioW...</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>disgust</td>\n      <td>/kaggle/input/emotion-sound-data/sound2/AudioW...</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}]},{"cell_type":"markdown","source":"# TESS","metadata":{}},{"cell_type":"code","source":"tess_path = \"/kaggle/input/emotion-sound-data/sound3/TESS Toronto emotional speech set data/\"\n\n","metadata":{"execution":{"iopub.status.busy":"2024-07-02T10:25:04.823510Z","iopub.execute_input":"2024-07-02T10:25:04.823842Z","iopub.status.idle":"2024-07-02T10:25:04.831814Z","shell.execute_reply.started":"2024-07-02T10:25:04.823814Z","shell.execute_reply":"2024-07-02T10:25:04.830747Z"},"trusted":true},"execution_count":15,"outputs":[]},{"cell_type":"code","source":"tess_directory_list = os.listdir(tess_path)\n\nfile_emotion = []\nfile_path = []","metadata":{"execution":{"iopub.status.busy":"2024-07-02T10:25:04.836842Z","iopub.execute_input":"2024-07-02T10:25:04.837473Z","iopub.status.idle":"2024-07-02T10:25:04.847375Z","shell.execute_reply.started":"2024-07-02T10:25:04.837435Z","shell.execute_reply":"2024-07-02T10:25:04.846226Z"},"trusted":true},"execution_count":16,"outputs":[]},{"cell_type":"code","source":"tess_files = [f for f in os.listdir(tess_path) if f.endswith('.wav')]\nprint(tess_files[:5])","metadata":{"execution":{"iopub.status.busy":"2024-07-02T10:25:04.848902Z","iopub.execute_input":"2024-07-02T10:25:04.849658Z","iopub.status.idle":"2024-07-02T10:25:04.857106Z","shell.execute_reply.started":"2024-07-02T10:25:04.849584Z","shell.execute_reply":"2024-07-02T10:25:04.855908Z"},"trusted":true},"execution_count":17,"outputs":[{"name":"stdout","text":"[]\n","output_type":"stream"}]},{"cell_type":"code","source":"for dir in tess_directory_list:\n    directories = os.listdir(tess_path + dir)\n    for file in directories:\n        part = file.split('.')[0]\n        part = part.split('_')[2]\n        if part=='ps':\n            file_emotion.append('surprise')\n        else:\n            file_emotion.append(part)\n        file_path.append(tess_path + dir + '/' + file)","metadata":{"execution":{"iopub.status.busy":"2024-07-02T10:25:04.858660Z","iopub.execute_input":"2024-07-02T10:25:04.859085Z","iopub.status.idle":"2024-07-02T10:25:05.454173Z","shell.execute_reply.started":"2024-07-02T10:25:04.859045Z","shell.execute_reply":"2024-07-02T10:25:05.452923Z"},"trusted":true},"execution_count":18,"outputs":[]},{"cell_type":"code","source":"# dataframe for emotion of files\nemotion_df = pd.DataFrame(file_emotion, columns=['Emotions'])","metadata":{"execution":{"iopub.status.busy":"2024-07-02T10:25:05.455823Z","iopub.execute_input":"2024-07-02T10:25:05.456744Z","iopub.status.idle":"2024-07-02T10:25:05.463126Z","shell.execute_reply.started":"2024-07-02T10:25:05.456695Z","shell.execute_reply":"2024-07-02T10:25:05.461843Z"},"trusted":true},"execution_count":19,"outputs":[]},{"cell_type":"code","source":"# dataframe for path of files.\npath_df = pd.DataFrame(file_path, columns=['Path'])\nTess_df = pd.concat([emotion_df, path_df], axis=1)\nTess_df.head()","metadata":{"execution":{"iopub.status.busy":"2024-07-02T10:25:05.465122Z","iopub.execute_input":"2024-07-02T10:25:05.465836Z","iopub.status.idle":"2024-07-02T10:25:05.484072Z","shell.execute_reply.started":"2024-07-02T10:25:05.465800Z","shell.execute_reply":"2024-07-02T10:25:05.482836Z"},"trusted":true},"execution_count":20,"outputs":[{"execution_count":20,"output_type":"execute_result","data":{"text/plain":"  Emotions                                               Path\n0     fear  /kaggle/input/emotion-sound-data/sound3/TESS T...\n1     fear  /kaggle/input/emotion-sound-data/sound3/TESS T...\n2     fear  /kaggle/input/emotion-sound-data/sound3/TESS T...\n3     fear  /kaggle/input/emotion-sound-data/sound3/TESS T...\n4     fear  /kaggle/input/emotion-sound-data/sound3/TESS T...","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Emotions</th>\n      <th>Path</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>fear</td>\n      <td>/kaggle/input/emotion-sound-data/sound3/TESS T...</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>fear</td>\n      <td>/kaggle/input/emotion-sound-data/sound3/TESS T...</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>fear</td>\n      <td>/kaggle/input/emotion-sound-data/sound3/TESS T...</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>fear</td>\n      <td>/kaggle/input/emotion-sound-data/sound3/TESS T...</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>fear</td>\n      <td>/kaggle/input/emotion-sound-data/sound3/TESS T...</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}]},{"cell_type":"markdown","source":"# SAVEE","metadata":{}},{"cell_type":"code","source":"savee_path = \"/kaggle/input/emotion-sound-data/sound4/ALL\"\nsavee_files = [f for f in os.listdir(savee_path) if f.endswith('.wav')]\nprint(savee_files[:5])\n","metadata":{"execution":{"iopub.status.busy":"2024-07-02T10:25:05.485517Z","iopub.execute_input":"2024-07-02T10:25:05.485983Z","iopub.status.idle":"2024-07-02T10:25:05.585522Z","shell.execute_reply.started":"2024-07-02T10:25:05.485946Z","shell.execute_reply":"2024-07-02T10:25:05.584377Z"},"trusted":true},"execution_count":21,"outputs":[{"name":"stdout","text":"['JE_h09.wav', 'KL_f12.wav', 'DC_h03.wav', 'DC_d04.wav', 'KL_a14.wav']\n","output_type":"stream"}]},{"cell_type":"code","source":"savee_directory_list = os.listdir(savee_path)\n\nfile_emotion = []\nfile_path = []","metadata":{"execution":{"iopub.status.busy":"2024-07-02T10:25:05.586755Z","iopub.execute_input":"2024-07-02T10:25:05.587191Z","iopub.status.idle":"2024-07-02T10:25:05.594577Z","shell.execute_reply.started":"2024-07-02T10:25:05.587154Z","shell.execute_reply":"2024-07-02T10:25:05.593514Z"},"trusted":true},"execution_count":22,"outputs":[]},{"cell_type":"code","source":"for file in savee_directory_list:\n    file_path.append(savee_path + file)\n    part = file.split('_')[1]\n    ele = part[:-6]\n    if ele=='a':\n        file_emotion.append('angry')\n    elif ele=='d':\n        file_emotion.append('disgust')\n    elif ele=='f':\n        file_emotion.append('fear')\n    elif ele=='h':\n        file_emotion.append('happy')\n    elif ele=='n':\n        file_emotion.append('neutral')\n    elif ele=='sa':\n        file_emotion.append('sad')\n    else:\n        file_emotion.append('surprise')","metadata":{"execution":{"iopub.status.busy":"2024-07-02T10:25:05.596273Z","iopub.execute_input":"2024-07-02T10:25:05.597192Z","iopub.status.idle":"2024-07-02T10:25:05.608703Z","shell.execute_reply.started":"2024-07-02T10:25:05.597146Z","shell.execute_reply":"2024-07-02T10:25:05.607411Z"},"trusted":true},"execution_count":23,"outputs":[]},{"cell_type":"code","source":"# dataframe for emotion of files\nemotion_df = pd.DataFrame(file_emotion, columns=['Emotions'])","metadata":{"execution":{"iopub.status.busy":"2024-07-02T10:25:05.611106Z","iopub.execute_input":"2024-07-02T10:25:05.613186Z","iopub.status.idle":"2024-07-02T10:25:05.625146Z","shell.execute_reply.started":"2024-07-02T10:25:05.612838Z","shell.execute_reply":"2024-07-02T10:25:05.623572Z"},"trusted":true},"execution_count":24,"outputs":[]},{"cell_type":"code","source":"# dataframe for path of files.\npath_df = pd.DataFrame(file_path, columns=['Path'])\nSavee_df = pd.concat([emotion_df, path_df], axis=1)\nSavee_df.head()","metadata":{"execution":{"iopub.status.busy":"2024-07-02T10:25:05.629176Z","iopub.execute_input":"2024-07-02T10:25:05.630338Z","iopub.status.idle":"2024-07-02T10:25:05.659466Z","shell.execute_reply.started":"2024-07-02T10:25:05.630290Z","shell.execute_reply":"2024-07-02T10:25:05.658295Z"},"trusted":true},"execution_count":25,"outputs":[{"execution_count":25,"output_type":"execute_result","data":{"text/plain":"  Emotions                                               Path\n0    happy  /kaggle/input/emotion-sound-data/sound4/ALLJE_...\n1     fear  /kaggle/input/emotion-sound-data/sound4/ALLKL_...\n2    happy  /kaggle/input/emotion-sound-data/sound4/ALLDC_...\n3  disgust  /kaggle/input/emotion-sound-data/sound4/ALLDC_...\n4    angry  /kaggle/input/emotion-sound-data/sound4/ALLKL_...","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Emotions</th>\n      <th>Path</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>happy</td>\n      <td>/kaggle/input/emotion-sound-data/sound4/ALLJE_...</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>fear</td>\n      <td>/kaggle/input/emotion-sound-data/sound4/ALLKL_...</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>happy</td>\n      <td>/kaggle/input/emotion-sound-data/sound4/ALLDC_...</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>disgust</td>\n      <td>/kaggle/input/emotion-sound-data/sound4/ALLDC_...</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>angry</td>\n      <td>/kaggle/input/emotion-sound-data/sound4/ALLKL_...</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# chatgpt\n","metadata":{}},{"cell_type":"code","source":"import librosa\nimport numpy as np\n\ndef extract_features(file_path):\n    audio, sample_rate = librosa.load(file_path, res_type='kaiser_fast')\n    mfccs = librosa.feature.mfcc(y=audio, sr=sample_rate, n_mfcc=40)\n    mfccs_scaled = np.mean(mfccs.T, axis=0)\n    return mfccs_scaled\n","metadata":{"execution":{"iopub.status.busy":"2024-07-02T10:14:58.230264Z","iopub.execute_input":"2024-07-02T10:14:58.230708Z","iopub.status.idle":"2024-07-02T10:14:58.245288Z","shell.execute_reply.started":"2024-07-02T10:14:58.230673Z","shell.execute_reply":"2024-07-02T10:14:58.243918Z"},"trusted":true},"execution_count":39,"outputs":[]},{"cell_type":"code","source":"!pip install resampy\n","metadata":{"execution":{"iopub.status.busy":"2024-07-02T10:16:42.354699Z","iopub.execute_input":"2024-07-02T10:16:42.355157Z","iopub.status.idle":"2024-07-02T10:16:58.977249Z","shell.execute_reply.started":"2024-07-02T10:16:42.355124Z","shell.execute_reply":"2024-07-02T10:16:58.975895Z"},"trusted":true},"execution_count":42,"outputs":[{"name":"stdout","text":"Collecting resampy\n  Downloading resampy-0.4.3-py3-none-any.whl.metadata (3.0 kB)\nRequirement already satisfied: numpy>=1.17 in /opt/conda/lib/python3.10/site-packages (from resampy) (1.26.4)\nRequirement already satisfied: numba>=0.53 in /opt/conda/lib/python3.10/site-packages (from resampy) (0.58.1)\nRequirement already satisfied: llvmlite<0.42,>=0.41.0dev0 in /opt/conda/lib/python3.10/site-packages (from numba>=0.53->resampy) (0.41.1)\nDownloading resampy-0.4.3-py3-none-any.whl (3.1 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.1/3.1 MB\u001b[0m \u001b[31m29.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n\u001b[?25hInstalling collected packages: resampy\nSuccessfully installed resampy-0.4.3\n","output_type":"stream"}]},{"cell_type":"code","source":"!pip install numpy pandas librosa scikit-learn tensorflow keras resampy\n","metadata":{"execution":{"iopub.status.busy":"2024-07-02T10:17:14.695503Z","iopub.execute_input":"2024-07-02T10:17:14.695971Z","iopub.status.idle":"2024-07-02T10:17:32.959447Z","shell.execute_reply.started":"2024-07-02T10:17:14.695938Z","shell.execute_reply":"2024-07-02T10:17:32.958014Z"},"trusted":true},"execution_count":45,"outputs":[{"name":"stdout","text":"Requirement already satisfied: numpy in /opt/conda/lib/python3.10/site-packages (1.26.4)\nRequirement already satisfied: pandas in /opt/conda/lib/python3.10/site-packages (2.2.2)\nRequirement already satisfied: librosa in /opt/conda/lib/python3.10/site-packages (0.10.2.post1)\nRequirement already satisfied: scikit-learn in /opt/conda/lib/python3.10/site-packages (1.2.2)\nRequirement already satisfied: tensorflow in /opt/conda/lib/python3.10/site-packages (2.15.0)\nRequirement already satisfied: keras in /opt/conda/lib/python3.10/site-packages (3.3.3)\nRequirement already satisfied: resampy in /opt/conda/lib/python3.10/site-packages (0.4.3)\nRequirement already satisfied: python-dateutil>=2.8.2 in /opt/conda/lib/python3.10/site-packages (from pandas) (2.9.0.post0)\nRequirement already satisfied: pytz>=2020.1 in /opt/conda/lib/python3.10/site-packages (from pandas) (2023.3.post1)\nRequirement already satisfied: tzdata>=2022.7 in /opt/conda/lib/python3.10/site-packages (from pandas) (2023.4)\nRequirement already satisfied: audioread>=2.1.9 in /opt/conda/lib/python3.10/site-packages (from librosa) (3.0.1)\nRequirement already satisfied: scipy>=1.2.0 in /opt/conda/lib/python3.10/site-packages (from librosa) (1.11.4)\nRequirement already satisfied: joblib>=0.14 in /opt/conda/lib/python3.10/site-packages (from librosa) (1.4.2)\nRequirement already satisfied: decorator>=4.3.0 in /opt/conda/lib/python3.10/site-packages (from librosa) (5.1.1)\nRequirement already satisfied: numba>=0.51.0 in /opt/conda/lib/python3.10/site-packages (from librosa) (0.58.1)\nRequirement already satisfied: soundfile>=0.12.1 in /opt/conda/lib/python3.10/site-packages (from librosa) (0.12.1)\nRequirement already satisfied: pooch>=1.1 in /opt/conda/lib/python3.10/site-packages (from librosa) (1.8.1)\nRequirement already satisfied: soxr>=0.3.2 in /opt/conda/lib/python3.10/site-packages (from librosa) (0.3.7)\nRequirement already satisfied: typing-extensions>=4.1.1 in /opt/conda/lib/python3.10/site-packages (from librosa) (4.9.0)\nRequirement already satisfied: lazy-loader>=0.1 in /opt/conda/lib/python3.10/site-packages (from librosa) (0.3)\nRequirement already satisfied: msgpack>=1.0 in /opt/conda/lib/python3.10/site-packages (from librosa) (1.0.7)\nRequirement already satisfied: threadpoolctl>=2.0.0 in /opt/conda/lib/python3.10/site-packages (from scikit-learn) (3.2.0)\nRequirement already satisfied: absl-py>=1.0.0 in /opt/conda/lib/python3.10/site-packages (from tensorflow) (1.4.0)\nRequirement already satisfied: astunparse>=1.6.0 in /opt/conda/lib/python3.10/site-packages (from tensorflow) (1.6.3)\nRequirement already satisfied: flatbuffers>=23.5.26 in /opt/conda/lib/python3.10/site-packages (from tensorflow) (23.5.26)\nRequirement already satisfied: gast!=0.5.0,!=0.5.1,!=0.5.2,>=0.2.1 in /opt/conda/lib/python3.10/site-packages (from tensorflow) (0.5.4)\nRequirement already satisfied: google-pasta>=0.1.1 in /opt/conda/lib/python3.10/site-packages (from tensorflow) (0.2.0)\nRequirement already satisfied: h5py>=2.9.0 in /opt/conda/lib/python3.10/site-packages (from tensorflow) (3.10.0)\nRequirement already satisfied: libclang>=13.0.0 in /opt/conda/lib/python3.10/site-packages (from tensorflow) (16.0.6)\nRequirement already satisfied: ml-dtypes~=0.2.0 in /opt/conda/lib/python3.10/site-packages (from tensorflow) (0.2.0)\nRequirement already satisfied: opt-einsum>=2.3.2 in /opt/conda/lib/python3.10/site-packages (from tensorflow) (3.3.0)\nRequirement already satisfied: packaging in /opt/conda/lib/python3.10/site-packages (from tensorflow) (21.3)\nRequirement already satisfied: protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0dev,>=3.20.3 in /opt/conda/lib/python3.10/site-packages (from tensorflow) (3.20.3)\nRequirement already satisfied: setuptools in /opt/conda/lib/python3.10/site-packages (from tensorflow) (69.0.3)\nRequirement already satisfied: six>=1.12.0 in /opt/conda/lib/python3.10/site-packages (from tensorflow) (1.16.0)\nRequirement already satisfied: termcolor>=1.1.0 in /opt/conda/lib/python3.10/site-packages (from tensorflow) (2.4.0)\nRequirement already satisfied: wrapt<1.15,>=1.11.0 in /opt/conda/lib/python3.10/site-packages (from tensorflow) (1.14.1)\nRequirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in /opt/conda/lib/python3.10/site-packages (from tensorflow) (0.35.0)\nRequirement already satisfied: grpcio<2.0,>=1.24.3 in /opt/conda/lib/python3.10/site-packages (from tensorflow) (1.60.0)\nRequirement already satisfied: tensorboard<2.16,>=2.15 in /opt/conda/lib/python3.10/site-packages (from tensorflow) (2.15.1)\nRequirement already satisfied: tensorflow-estimator<2.16,>=2.15.0 in /opt/conda/lib/python3.10/site-packages (from tensorflow) (2.15.0)\nCollecting keras\n  Downloading keras-2.15.0-py3-none-any.whl.metadata (2.4 kB)\nRequirement already satisfied: wheel<1.0,>=0.23.0 in /opt/conda/lib/python3.10/site-packages (from astunparse>=1.6.0->tensorflow) (0.42.0)\nRequirement already satisfied: llvmlite<0.42,>=0.41.0dev0 in /opt/conda/lib/python3.10/site-packages (from numba>=0.51.0->librosa) (0.41.1)\nRequirement already satisfied: platformdirs>=2.5.0 in /opt/conda/lib/python3.10/site-packages (from pooch>=1.1->librosa) (3.11.0)\nRequirement already satisfied: requests>=2.19.0 in /opt/conda/lib/python3.10/site-packages (from pooch>=1.1->librosa) (2.32.3)\nRequirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /opt/conda/lib/python3.10/site-packages (from packaging->tensorflow) (3.1.1)\nRequirement already satisfied: cffi>=1.0 in /opt/conda/lib/python3.10/site-packages (from soundfile>=0.12.1->librosa) (1.16.0)\nRequirement already satisfied: google-auth<3,>=1.6.3 in /opt/conda/lib/python3.10/site-packages (from tensorboard<2.16,>=2.15->tensorflow) (2.26.1)\nRequirement already satisfied: google-auth-oauthlib<2,>=0.5 in /opt/conda/lib/python3.10/site-packages (from tensorboard<2.16,>=2.15->tensorflow) (1.2.0)\nRequirement already satisfied: markdown>=2.6.8 in /opt/conda/lib/python3.10/site-packages (from tensorboard<2.16,>=2.15->tensorflow) (3.5.2)\nRequirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /opt/conda/lib/python3.10/site-packages (from tensorboard<2.16,>=2.15->tensorflow) (0.7.2)\nRequirement already satisfied: werkzeug>=1.0.1 in /opt/conda/lib/python3.10/site-packages (from tensorboard<2.16,>=2.15->tensorflow) (3.0.3)\nRequirement already satisfied: pycparser in /opt/conda/lib/python3.10/site-packages (from cffi>=1.0->soundfile>=0.12.1->librosa) (2.21)\nRequirement already satisfied: cachetools<6.0,>=2.0.0 in /opt/conda/lib/python3.10/site-packages (from google-auth<3,>=1.6.3->tensorboard<2.16,>=2.15->tensorflow) (4.2.4)\nRequirement already satisfied: pyasn1-modules>=0.2.1 in /opt/conda/lib/python3.10/site-packages (from google-auth<3,>=1.6.3->tensorboard<2.16,>=2.15->tensorflow) (0.3.0)\nRequirement already satisfied: rsa<5,>=3.1.4 in /opt/conda/lib/python3.10/site-packages (from google-auth<3,>=1.6.3->tensorboard<2.16,>=2.15->tensorflow) (4.9)\nRequirement already satisfied: requests-oauthlib>=0.7.0 in /opt/conda/lib/python3.10/site-packages (from google-auth-oauthlib<2,>=0.5->tensorboard<2.16,>=2.15->tensorflow) (1.3.1)\nRequirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.10/site-packages (from requests>=2.19.0->pooch>=1.1->librosa) (3.3.2)\nRequirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.10/site-packages (from requests>=2.19.0->pooch>=1.1->librosa) (3.6)\nRequirement already satisfied: urllib3<3,>=1.21.1 in /opt/conda/lib/python3.10/site-packages (from requests>=2.19.0->pooch>=1.1->librosa) (1.26.18)\nRequirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.10/site-packages (from requests>=2.19.0->pooch>=1.1->librosa) (2024.2.2)\nRequirement already satisfied: MarkupSafe>=2.1.1 in /opt/conda/lib/python3.10/site-packages (from werkzeug>=1.0.1->tensorboard<2.16,>=2.15->tensorflow) (2.1.3)\nRequirement already satisfied: pyasn1<0.6.0,>=0.4.6 in /opt/conda/lib/python3.10/site-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard<2.16,>=2.15->tensorflow) (0.5.1)\nRequirement already satisfied: oauthlib>=3.0.0 in /opt/conda/lib/python3.10/site-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<2,>=0.5->tensorboard<2.16,>=2.15->tensorflow) (3.2.2)\nDownloading keras-2.15.0-py3-none-any.whl (1.7 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.7/1.7 MB\u001b[0m \u001b[31m23.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hInstalling collected packages: keras\n  Attempting uninstall: keras\n    Found existing installation: keras 3.3.3\n    Uninstalling keras-3.3.3:\n      Successfully uninstalled keras-3.3.3\n\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\ntensorflow-decision-forests 1.8.1 requires wurlitzer, which is not installed.\u001b[0m\u001b[31m\n\u001b[0mSuccessfully installed keras-2.15.0\n","output_type":"stream"}]},{"cell_type":"code","source":"def load_data(file_list, base_path):\n    features = []\n    labels = []\n    for file_name in file_list:\n        file_path = os.path.join(base_path, file_name)\n        mfccs = extract_features(file_path)\n        features.append(mfccs)\n        \n        # Extract label from filename (example for RAVDESS)\n        label = int(file_name.split('-')[2]) - 1\n        labels.append(label)\n    \n    return np.array(features), np.array(labels)\n\nravdess_features, ravdess_labels = load_data(ravdess_files, ravdess_path)\ncremad_features, cremad_labels = load_data(cremad_files, cremad_path)\ntess_features, tess_labels = load_data(tess_files, tess_path)\nsavee_features, savee_labels = load_data(savee_files, savee_path)\n","metadata":{"execution":{"iopub.status.busy":"2024-07-02T10:17:41.195192Z","iopub.execute_input":"2024-07-02T10:17:41.196442Z","iopub.status.idle":"2024-07-02T10:17:41.405574Z","shell.execute_reply.started":"2024-07-02T10:17:41.196395Z","shell.execute_reply":"2024-07-02T10:17:41.403611Z"},"trusted":true},"execution_count":46,"outputs":[{"traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)","Cell \u001b[0;32mIn[46], line 16\u001b[0m\n\u001b[1;32m     13\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m np\u001b[38;5;241m.\u001b[39marray(features), np\u001b[38;5;241m.\u001b[39marray(labels)\n\u001b[1;32m     15\u001b[0m ravdess_features, ravdess_labels \u001b[38;5;241m=\u001b[39m load_data(ravdess_files, ravdess_path)\n\u001b[0;32m---> 16\u001b[0m cremad_features, cremad_labels \u001b[38;5;241m=\u001b[39m \u001b[43mload_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcremad_files\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcremad_path\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     17\u001b[0m tess_features, tess_labels \u001b[38;5;241m=\u001b[39m load_data(tess_files, tess_path)\n\u001b[1;32m     18\u001b[0m savee_features, savee_labels \u001b[38;5;241m=\u001b[39m load_data(savee_files, savee_path)\n","Cell \u001b[0;32mIn[46], line 6\u001b[0m, in \u001b[0;36mload_data\u001b[0;34m(file_list, base_path)\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m file_name \u001b[38;5;129;01min\u001b[39;00m file_list:\n\u001b[1;32m      5\u001b[0m     file_path \u001b[38;5;241m=\u001b[39m os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mjoin(base_path, file_name)\n\u001b[0;32m----> 6\u001b[0m     mfccs \u001b[38;5;241m=\u001b[39m \u001b[43mextract_features\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfile_path\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      7\u001b[0m     features\u001b[38;5;241m.\u001b[39mappend(mfccs)\n\u001b[1;32m      9\u001b[0m     \u001b[38;5;66;03m# Extract label from filename (example for RAVDESS)\u001b[39;00m\n","Cell \u001b[0;32mIn[39], line 5\u001b[0m, in \u001b[0;36mextract_features\u001b[0;34m(file_path)\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mextract_features\u001b[39m(file_path):\n\u001b[0;32m----> 5\u001b[0m     audio, sample_rate \u001b[38;5;241m=\u001b[39m \u001b[43mlibrosa\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mload\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfile_path\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mres_type\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mkaiser_fast\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m      6\u001b[0m     mfccs \u001b[38;5;241m=\u001b[39m librosa\u001b[38;5;241m.\u001b[39mfeature\u001b[38;5;241m.\u001b[39mmfcc(y\u001b[38;5;241m=\u001b[39maudio, sr\u001b[38;5;241m=\u001b[39msample_rate, n_mfcc\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m40\u001b[39m)\n\u001b[1;32m      7\u001b[0m     mfccs_scaled \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mmean(mfccs\u001b[38;5;241m.\u001b[39mT, axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m)\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/librosa/core/audio.py:193\u001b[0m, in \u001b[0;36mload\u001b[0;34m(path, sr, mono, offset, duration, dtype, res_type)\u001b[0m\n\u001b[1;32m    190\u001b[0m     y \u001b[38;5;241m=\u001b[39m to_mono(y)\n\u001b[1;32m    192\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m sr \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m--> 193\u001b[0m     y \u001b[38;5;241m=\u001b[39m \u001b[43mresample\u001b[49m\u001b[43m(\u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43morig_sr\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msr_native\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtarget_sr\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msr\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mres_type\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mres_type\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    195\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    196\u001b[0m     sr \u001b[38;5;241m=\u001b[39m sr_native\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/librosa/core/audio.py:678\u001b[0m, in \u001b[0;36mresample\u001b[0;34m(y, orig_sr, target_sr, res_type, fix, scale, axis, **kwargs)\u001b[0m\n\u001b[1;32m    669\u001b[0m     y_hat \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mapply_along_axis(\n\u001b[1;32m    670\u001b[0m         soxr\u001b[38;5;241m.\u001b[39mresample,\n\u001b[1;32m    671\u001b[0m         axis\u001b[38;5;241m=\u001b[39maxis,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    675\u001b[0m         quality\u001b[38;5;241m=\u001b[39mres_type,\n\u001b[1;32m    676\u001b[0m     )\n\u001b[1;32m    677\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 678\u001b[0m     y_hat \u001b[38;5;241m=\u001b[39m \u001b[43mresampy\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mresample\u001b[49m(y, orig_sr, target_sr, \u001b[38;5;28mfilter\u001b[39m\u001b[38;5;241m=\u001b[39mres_type, axis\u001b[38;5;241m=\u001b[39maxis)\n\u001b[1;32m    680\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m fix:\n\u001b[1;32m    681\u001b[0m     y_hat \u001b[38;5;241m=\u001b[39m util\u001b[38;5;241m.\u001b[39mfix_length(y_hat, size\u001b[38;5;241m=\u001b[39mn_samples, axis\u001b[38;5;241m=\u001b[39maxis, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/lazy_loader/__init__.py:111\u001b[0m, in \u001b[0;36mDelayedImportErrorModule.__getattr__\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m    109\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    110\u001b[0m     fd \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m__frame_data\n\u001b[0;32m--> 111\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mModuleNotFoundError\u001b[39;00m(\n\u001b[1;32m    112\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mNo module named \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfd[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mspec\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    113\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mThis error is lazily reported, having originally occured in\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    114\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m  File \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfd[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mfilename\u001b[39m\u001b[38;5;124m\"\u001b[39m]\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m, line \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfd[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mlineno\u001b[39m\u001b[38;5;124m\"\u001b[39m]\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m, in \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfd[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mfunction\u001b[39m\u001b[38;5;124m\"\u001b[39m]\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m    115\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m----> \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mjoin(fd[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcode_context\u001b[39m\u001b[38;5;124m\"\u001b[39m])\u001b[38;5;241m.\u001b[39mstrip()\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m    116\u001b[0m     )\n","\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'resampy'\n\nThis error is lazily reported, having originally occured in\n  File /opt/conda/lib/python3.10/site-packages/librosa/core/audio.py, line 33, in <module>\n\n----> resampy = lazy.load(\"resampy\")"],"ename":"ModuleNotFoundError","evalue":"No module named 'resampy'\n\nThis error is lazily reported, having originally occured in\n  File /opt/conda/lib/python3.10/site-packages/librosa/core/audio.py, line 33, in <module>\n\n----> resampy = lazy.load(\"resampy\")","output_type":"error"}]},{"cell_type":"code","source":"X = np.concatenate((ravdess_features, cremad_features, tess_features, savee_features), axis=0)\ny = np.concatenate((ravdess_labels, cremad_labels, tess_labels, savee_labels), axis=0)\n","metadata":{"execution":{"iopub.status.busy":"2024-07-02T10:17:02.724239Z","iopub.execute_input":"2024-07-02T10:17:02.724626Z","iopub.status.idle":"2024-07-02T10:17:02.774993Z","shell.execute_reply.started":"2024-07-02T10:17:02.724597Z","shell.execute_reply":"2024-07-02T10:17:02.773130Z"},"trusted":true},"execution_count":44,"outputs":[{"traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)","Cell \u001b[0;32mIn[44], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m X \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mconcatenate((ravdess_features, \u001b[43mcremad_features\u001b[49m, tess_features, savee_features), axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m)\n\u001b[1;32m      2\u001b[0m y \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mconcatenate((ravdess_labels, cremad_labels, tess_labels, savee_labels), axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m)\n","\u001b[0;31mNameError\u001b[0m: name 'cremad_features' is not defined"],"ename":"NameError","evalue":"name 'cremad_features' is not defined","output_type":"error"}]},{"cell_type":"code","source":"from sklearn.model_selection import train_test_split\n\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n","metadata":{"execution":{"iopub.status.busy":"2024-07-02T10:15:38.782715Z","iopub.status.idle":"2024-07-02T10:15:38.783308Z","shell.execute_reply.started":"2024-07-02T10:15:38.783007Z","shell.execute_reply":"2024-07-02T10:15:38.783029Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from tensorflow.keras.models import Sequential\nfrom tensorflow.keras.layers import Dense, Dropout\n\nmodel = Sequential()\nmodel.add(Dense(256, input_shape=(X_train.shape[1],), activation='relu'))\nmodel.add(Dropout(0.5))\nmodel.add(Dense(128, activation='relu'))\nmodel.add(Dropout(0.5))\nmodel.add(Dense(64, activation='relu'))\nmodel.add(Dense(8, activation='softmax'))  # Assuming 8 emotion classes\n\nmodel.compile(loss='sparse_categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n","metadata":{"execution":{"iopub.status.busy":"2024-07-02T10:15:45.447253Z","iopub.execute_input":"2024-07-02T10:15:45.447673Z","iopub.status.idle":"2024-07-02T10:16:00.840138Z","shell.execute_reply.started":"2024-07-02T10:15:45.447640Z","shell.execute_reply":"2024-07-02T10:16:00.838162Z"},"trusted":true},"execution_count":41,"outputs":[{"name":"stderr","text":"2024-07-02 10:15:47.796369: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n2024-07-02 10:15:47.796684: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n2024-07-02 10:15:47.975241: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n","output_type":"stream"},{"traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)","Cell \u001b[0;32mIn[41], line 5\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mkeras\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mlayers\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Dense, Dropout\n\u001b[1;32m      4\u001b[0m model \u001b[38;5;241m=\u001b[39m Sequential()\n\u001b[0;32m----> 5\u001b[0m model\u001b[38;5;241m.\u001b[39madd(Dense(\u001b[38;5;241m256\u001b[39m, input_shape\u001b[38;5;241m=\u001b[39m(\u001b[43mX_train\u001b[49m\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m1\u001b[39m],), activation\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mrelu\u001b[39m\u001b[38;5;124m'\u001b[39m))\n\u001b[1;32m      6\u001b[0m model\u001b[38;5;241m.\u001b[39madd(Dropout(\u001b[38;5;241m0.5\u001b[39m))\n\u001b[1;32m      7\u001b[0m model\u001b[38;5;241m.\u001b[39madd(Dense(\u001b[38;5;241m128\u001b[39m, activation\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mrelu\u001b[39m\u001b[38;5;124m'\u001b[39m))\n","\u001b[0;31mNameError\u001b[0m: name 'X_train' is not defined"],"ename":"NameError","evalue":"name 'X_train' is not defined","output_type":"error"}]},{"cell_type":"code","source":"history = model.fit(X_train, y_train, epochs=50, batch_size=32, validation_data=(X_test, y_test))\n","metadata":{"execution":{"iopub.status.busy":"2024-07-02T10:16:00.841256Z","iopub.status.idle":"2024-07-02T10:16:00.841664Z","shell.execute_reply.started":"2024-07-02T10:16:00.841472Z","shell.execute_reply":"2024-07-02T10:16:00.841489Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import pandas as pd\nimport numpy as np\n\nimport os\nimport sys\n\n# librosa is a Python library for analyzing audio and music. It can be used to extract the data from the audio files we will see it later.\nimport librosa\nimport librosa.display\nimport seaborn as sns\nimport matplotlib.pyplot as plt\n\nfrom sklearn.preprocessing import StandardScaler, OneHotEncoder\nfrom sklearn.metrics import confusion_matrix, classification_report\nfrom sklearn.model_selection import train_test_split","metadata":{"execution":{"iopub.status.busy":"2024-07-02T10:27:43.081225Z","iopub.execute_input":"2024-07-02T10:27:43.081957Z","iopub.status.idle":"2024-07-02T10:27:43.087550Z","shell.execute_reply.started":"2024-07-02T10:27:43.081920Z","shell.execute_reply":"2024-07-02T10:27:43.086406Z"},"trusted":true},"execution_count":29,"outputs":[]},{"cell_type":"code","source":"# to play the audio files\nfrom IPython.display import Audio\n\nimport keras","metadata":{"execution":{"iopub.status.busy":"2024-07-02T10:27:51.231155Z","iopub.execute_input":"2024-07-02T10:27:51.231559Z","iopub.status.idle":"2024-07-02T10:27:51.236401Z","shell.execute_reply.started":"2024-07-02T10:27:51.231525Z","shell.execute_reply":"2024-07-02T10:27:51.235209Z"},"trusted":true},"execution_count":30,"outputs":[]},{"cell_type":"code","source":"from keras.callbacks import ReduceLROnPlateau\nfrom keras.models import Sequential","metadata":{"execution":{"iopub.status.busy":"2024-07-02T10:27:58.649863Z","iopub.execute_input":"2024-07-02T10:27:58.650256Z","iopub.status.idle":"2024-07-02T10:27:58.657537Z","shell.execute_reply.started":"2024-07-02T10:27:58.650223Z","shell.execute_reply":"2024-07-02T10:27:58.656472Z"},"trusted":true},"execution_count":31,"outputs":[]},{"cell_type":"code","source":"from keras.layers import Dense, Conv1D, MaxPooling1D, Flatten, Dropout, BatchNormalization\nfrom keras.utils import to_categorical","metadata":{"execution":{"iopub.status.busy":"2024-07-02T10:28:12.890966Z","iopub.execute_input":"2024-07-02T10:28:12.891673Z","iopub.status.idle":"2024-07-02T10:28:12.896590Z","shell.execute_reply.started":"2024-07-02T10:28:12.891635Z","shell.execute_reply":"2024-07-02T10:28:12.895488Z"},"trusted":true},"execution_count":33,"outputs":[]},{"cell_type":"code","source":"from keras.callbacks import ModelCheckpoint","metadata":{"execution":{"iopub.status.busy":"2024-07-02T10:28:19.851743Z","iopub.execute_input":"2024-07-02T10:28:19.852130Z","iopub.status.idle":"2024-07-02T10:28:19.857236Z","shell.execute_reply.started":"2024-07-02T10:28:19.852098Z","shell.execute_reply":"2024-07-02T10:28:19.855949Z"},"trusted":true},"execution_count":34,"outputs":[]},{"cell_type":"markdown","source":"# kaggle","metadata":{}},{"cell_type":"code","source":"# creating Dataframe using all the 4 dataframes we created so far.\ndata_path = pd.concat([Ravdess_df, Crema_df, Tess_df, Savee_df], axis = 0)\ndata_path.to_csv(\"data_path.csv\",index=False)\ndata_path.head()","metadata":{"execution":{"iopub.status.busy":"2024-07-02T10:28:31.341213Z","iopub.execute_input":"2024-07-02T10:28:31.342590Z","iopub.status.idle":"2024-07-02T10:28:31.392896Z","shell.execute_reply.started":"2024-07-02T10:28:31.342537Z","shell.execute_reply":"2024-07-02T10:28:31.391641Z"},"trusted":true},"execution_count":35,"outputs":[{"execution_count":35,"output_type":"execute_result","data":{"text/plain":"   Emotions                                               Path\n0  surprise  /kaggle/input/emotion-sound-data/archive/audio...\n1   neutral  /kaggle/input/emotion-sound-data/archive/audio...\n2   disgust  /kaggle/input/emotion-sound-data/archive/audio...\n3   disgust  /kaggle/input/emotion-sound-data/archive/audio...\n4   neutral  /kaggle/input/emotion-sound-data/archive/audio...","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Emotions</th>\n      <th>Path</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>surprise</td>\n      <td>/kaggle/input/emotion-sound-data/archive/audio...</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>neutral</td>\n      <td>/kaggle/input/emotion-sound-data/archive/audio...</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>disgust</td>\n      <td>/kaggle/input/emotion-sound-data/archive/audio...</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>disgust</td>\n      <td>/kaggle/input/emotion-sound-data/archive/audio...</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>neutral</td>\n      <td>/kaggle/input/emotion-sound-data/archive/audio...</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"plt.title('Count of Emotions', size=16)\nsns.countplot(data_path.Emotions)\nplt.ylabel('Count', size=12)\nplt.xlabel('Emotions', size=12)\nsns.despine(top=True, right=True, left=False, bottom=False)\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2024-07-02T10:28:33.791611Z","iopub.execute_input":"2024-07-02T10:28:33.792111Z","iopub.status.idle":"2024-07-02T10:28:34.538169Z","shell.execute_reply.started":"2024-07-02T10:28:33.792072Z","shell.execute_reply":"2024-07-02T10:28:34.536283Z"},"trusted":true},"execution_count":36,"outputs":[{"traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)","Cell \u001b[0;32mIn[36], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m plt\u001b[38;5;241m.\u001b[39mtitle(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mCount of Emotions\u001b[39m\u001b[38;5;124m'\u001b[39m, size\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m16\u001b[39m)\n\u001b[0;32m----> 2\u001b[0m \u001b[43msns\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcountplot\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata_path\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mEmotions\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      3\u001b[0m plt\u001b[38;5;241m.\u001b[39mylabel(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mCount\u001b[39m\u001b[38;5;124m'\u001b[39m, size\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m12\u001b[39m)\n\u001b[1;32m      4\u001b[0m plt\u001b[38;5;241m.\u001b[39mxlabel(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mEmotions\u001b[39m\u001b[38;5;124m'\u001b[39m, size\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m12\u001b[39m)\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/seaborn/categorical.py:2943\u001b[0m, in \u001b[0;36mcountplot\u001b[0;34m(data, x, y, hue, order, hue_order, orient, color, palette, saturation, width, dodge, ax, **kwargs)\u001b[0m\n\u001b[1;32m   2940\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m x \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m y \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m   2941\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCannot pass values for both `x` and `y`\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m-> 2943\u001b[0m plotter \u001b[38;5;241m=\u001b[39m \u001b[43m_CountPlotter\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   2944\u001b[0m \u001b[43m    \u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mhue\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdata\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43morder\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mhue_order\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2945\u001b[0m \u001b[43m    \u001b[49m\u001b[43mestimator\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43merrorbar\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mn_boot\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43munits\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mseed\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2946\u001b[0m \u001b[43m    \u001b[49m\u001b[43morient\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcolor\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpalette\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msaturation\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2947\u001b[0m \u001b[43m    \u001b[49m\u001b[43mwidth\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43merrcolor\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43merrwidth\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcapsize\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdodge\u001b[49m\n\u001b[1;32m   2948\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   2950\u001b[0m plotter\u001b[38;5;241m.\u001b[39mvalue_label \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcount\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   2952\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m ax \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/seaborn/categorical.py:1530\u001b[0m, in \u001b[0;36m_BarPlotter.__init__\u001b[0;34m(self, x, y, hue, data, order, hue_order, estimator, errorbar, n_boot, units, seed, orient, color, palette, saturation, width, errcolor, errwidth, capsize, dodge)\u001b[0m\n\u001b[1;32m   1525\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__init__\u001b[39m(\u001b[38;5;28mself\u001b[39m, x, y, hue, data, order, hue_order,\n\u001b[1;32m   1526\u001b[0m              estimator, errorbar, n_boot, units, seed,\n\u001b[1;32m   1527\u001b[0m              orient, color, palette, saturation, width,\n\u001b[1;32m   1528\u001b[0m              errcolor, errwidth, capsize, dodge):\n\u001b[1;32m   1529\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Initialize the plotter.\"\"\"\u001b[39;00m\n\u001b[0;32m-> 1530\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mestablish_variables\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mhue\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdata\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43morient\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1531\u001b[0m \u001b[43m                             \u001b[49m\u001b[43morder\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mhue_order\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43munits\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1532\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mestablish_colors(color, palette, saturation)\n\u001b[1;32m   1533\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mestimate_statistic(estimator, errorbar, n_boot, seed)\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/seaborn/categorical.py:516\u001b[0m, in \u001b[0;36m_CategoricalPlotter.establish_variables\u001b[0;34m(self, x, y, hue, data, orient, order, hue_order, units)\u001b[0m\n\u001b[1;32m    513\u001b[0m     plot_data \u001b[38;5;241m=\u001b[39m data\n\u001b[1;32m    515\u001b[0m \u001b[38;5;66;03m# Convert to a list of arrays, the common representation\u001b[39;00m\n\u001b[0;32m--> 516\u001b[0m plot_data \u001b[38;5;241m=\u001b[39m [np\u001b[38;5;241m.\u001b[39masarray(d, \u001b[38;5;28mfloat\u001b[39m) \u001b[38;5;28;01mfor\u001b[39;00m d \u001b[38;5;129;01min\u001b[39;00m plot_data]\n\u001b[1;32m    518\u001b[0m \u001b[38;5;66;03m# The group names will just be numeric indices\u001b[39;00m\n\u001b[1;32m    519\u001b[0m group_names \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlist\u001b[39m(\u001b[38;5;28mrange\u001b[39m(\u001b[38;5;28mlen\u001b[39m(plot_data)))\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/seaborn/categorical.py:516\u001b[0m, in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    513\u001b[0m     plot_data \u001b[38;5;241m=\u001b[39m data\n\u001b[1;32m    515\u001b[0m \u001b[38;5;66;03m# Convert to a list of arrays, the common representation\u001b[39;00m\n\u001b[0;32m--> 516\u001b[0m plot_data \u001b[38;5;241m=\u001b[39m [\u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43masarray\u001b[49m\u001b[43m(\u001b[49m\u001b[43md\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mfloat\u001b[39;49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mfor\u001b[39;00m d \u001b[38;5;129;01min\u001b[39;00m plot_data]\n\u001b[1;32m    518\u001b[0m \u001b[38;5;66;03m# The group names will just be numeric indices\u001b[39;00m\n\u001b[1;32m    519\u001b[0m group_names \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlist\u001b[39m(\u001b[38;5;28mrange\u001b[39m(\u001b[38;5;28mlen\u001b[39m(plot_data)))\n","\u001b[0;31mValueError\u001b[0m: could not convert string to float: 'surprise'"],"ename":"ValueError","evalue":"could not convert string to float: 'surprise'","output_type":"error"},{"output_type":"display_data","data":{"text/plain":"<Figure size 640x480 with 1 Axes>","image/png":"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"},"metadata":{}}]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}